import tensorflow as tf
from tensorflow.keras import layers, models

# -------------------------------
# 1. Load Dataset
# -------------------------------
train_ds = tf.keras.utils.image_dataset_from_directory(
    "data/train",          # ðŸ‘ˆ path to your training folder
    image_size=(128, 128), # resize all images to 128x128
    batch_size=32
)

val_ds = tf.keras.utils.image_dataset_from_directory(
    "data/val",            # ðŸ‘ˆ path to your validation folder
    image_size=(128, 128),
    batch_size=32
)

# -------------------------------
# 2. Data Preprocessing
# -------------------------------
# Normalize pixel values to [0,1]
normalization_layer = layers.Rescaling(1./255)

# Data augmentation (instead of ImageDataGenerator)
data_augmentation = tf.keras.Sequential([
    layers.RandomFlip("horizontal_and_vertical"),
    layers.RandomRotation(0.2),
    layers.RandomZoom(0.1),
])

# Improve performance (prefetching for pipeline optimization)
AUTOTUNE = tf.data.AUTOTUNE
train_ds = train_ds.map(lambda x, y: (normalization_layer(x), y)).cache().shuffle(1000).prefetch(buffer_size=AUTOTUNE)
val_ds   = val_ds.map(lambda x, y: (normalization_layer(x), y)).cache().prefetch(buffer_size=AUTOTUNE)

# -------------------------------
# 3. Define CNN Model
# -------------------------------
model = models.Sequential([
    data_augmentation,   # ðŸ‘ˆ augmentation happens inside the model

    layers.Conv2D(32, (3, 3), activation='relu', input_shape=(128, 128, 3)),
    layers.MaxPooling2D((2, 2)),

    layers.Conv2D(64, (3, 3), activation='relu'),
    layers.MaxPooling2D((2, 2)),

    layers.Conv2D(128, (3, 3), activation='relu'),
    layers.MaxPooling2D((2, 2)),

    layers.Flatten(),
    layers.Dense(128, activation='relu'),
    layers.Dense(train_ds.cardinality().numpy(), activation='softmax')  # output classes = number of folders
])

# -------------------------------
# 4. Compile Model
# -------------------------------
model.compile(
    optimizer='adam',
    loss='sparse_categorical_crossentropy',
    metrics=['accuracy']
)

# -------------------------------
# 5. Train Model
# -------------------------------
history = model.fit(
    train_ds,
    validation_data=val_ds,
    epochs=10
)

# -------------------------------
# 6. Save Model
# -------------------------------
model.save("models/cnn_model.h5")
